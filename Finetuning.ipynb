{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1183165,"sourceType":"datasetVersion","datasetId":672377}],"dockerImageVersionId":30138,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import seaborn as sns\nimport numpy as np \nimport pandas as pd \nimport cv2\nimport matplotlib.pyplot as plt \nimport os\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nimport keras\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Conv2D\nfrom tensorflow.keras.optimizers import Adam \nfrom kerastuner import RandomSearch\nimport os\nimport numpy as np\nimport torch\nimport glob\nimport torch.nn as nn\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom torch.autograd import Variable\nimport torchvision\nimport pathlib\nimport pandas as pd\nimport numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\nfrom torch.optim import Adam, SGD\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\n\n\n# <p style=\"background-color:#808080;font-family:newtimeroman;color:#000000;font-size:150%;text-align:center;border-radius:40px 40px;\">Building Model Using Keras</p>","metadata":{"execution":{"iopub.status.busy":"2024-05-08T12:56:17.711847Z","iopub.execute_input":"2024-05-08T12:56:17.712535Z","iopub.status.idle":"2024-05-08T12:56:29.867374Z","shell.execute_reply.started":"2024-05-08T12:56:17.712425Z","shell.execute_reply":"2024-05-08T12:56:29.866258Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_img = []\ntrain_labels = []\n\ntest_img = []\ntest_labels = []\n\npath_train = ('/kaggle/input/brain-tumor-classification-mri/Training/')\npath_test = ('/kaggle/input/brain-tumor-classification-mri/Testing/')\nimg_size= 300\n\nfor i in os.listdir(path_train):\n    for j in os.listdir(path_train+i):\n        train_img.append (cv2.resize(cv2.imread(path_train+i+'/'+j), (img_size,img_size))) \n        train_labels.append(i)\n        \nfor i in os.listdir(path_test):\n    for j in os.listdir(path_test+i):\n        test_img.append (cv2.resize(cv2.imread(path_test+i+'/'+j), (img_size,img_size))) \n        test_labels.append(i)\n        \ntrain_img = (np.array(train_img))\ntest_img = (np.array(test_img))\n\n\ntrain_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(train_labels)]\ntest_labels_encoded = [0 if category == 'no_tumor' else(1 if category == 'glioma_tumor' else(2 if category=='meningioma_tumor' else 3)) for category in list(test_labels)]","metadata":{"execution":{"iopub.status.busy":"2024-05-08T12:56:29.869515Z","iopub.execute_input":"2024-05-08T12:56:29.869871Z","iopub.status.idle":"2024-05-08T12:57:01.969068Z","shell.execute_reply.started":"2024-05-08T12:56:29.869832Z","shell.execute_reply":"2024-05-08T12:57:01.968025Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\nimg_datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nimg_datagen.fit(train_img)\nimg_datagen.fit(test_img)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T12:57:01.981998Z","iopub.execute_input":"2024-05-08T12:57:01.982824Z","iopub.status.idle":"2024-05-08T12:57:04.982722Z","shell.execute_reply.started":"2024-05-08T12:57:01.982763Z","shell.execute_reply":"2024-05-08T12:57:04.981771Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Sequential(\n        [\n          tf.keras.layers.Conv2D(kernel_size=(5,5) ,filters=32, activation='relu', padding='same'),\n          tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n          tf.keras.layers.Conv2D(kernel_size=(3,3),filters=32, activation='relu', padding='same'),\n          tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n          tf.keras.layers.Conv2D(kernel_size=(3,3) ,filters=32, activation='relu', padding='same'),\n          tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n          tf.keras.layers.Conv2D(kernel_size=(3,3) ,filters=64, activation='relu', padding='same'),\n          tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n\n          tf.keras.layers.Flatten(),\n          tf.keras.layers.Dense(128, activation='relu'),\n          tf.keras.layers.Dropout(rate=0.5),\n          tf.keras.layers.Dense(4, activation='sigmoid')\n  ])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T12:57:06.281874Z","iopub.execute_input":"2024-05-08T12:57:06.282230Z","iopub.status.idle":"2024-05-08T12:57:06.398868Z","shell.execute_reply.started":"2024-05-08T12:57:06.282183Z","shell.execute_reply":"2024-05-08T12:57:06.398050Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\nUser settings:\n\n   KMP_AFFINITY=granularity=fine,verbose,compact,1,0\n   KMP_BLOCKTIME=0\n   KMP_DUPLICATE_LIB_OK=True\n   KMP_INIT_AT_FORK=FALSE\n   KMP_SETTINGS=1\n   KMP_WARNINGS=0\n\nEffective settings:\n\n   KMP_ABORT_DELAY=0\n   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n   KMP_ALIGN_ALLOC=64\n   KMP_ALL_THREADPRIVATE=128\n   KMP_ATOMIC_MODE=2\n   KMP_BLOCKTIME=0\n   KMP_CPUINFO_FILE: value is not defined\n   KMP_DETERMINISTIC_REDUCTION=false\n   KMP_DEVICE_THREAD_LIMIT=2147483647\n   KMP_DISP_NUM_BUFFERS=7\n   KMP_DUPLICATE_LIB_OK=true\n   KMP_ENABLE_TASK_THROTTLING=true\n   KMP_FORCE_REDUCTION: value is not defined\n   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n   KMP_FORKJOIN_BARRIER='2,2'\n   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_GTID_MODE=3\n   KMP_HANDLE_SIGNALS=false\n   KMP_HOT_TEAMS_MAX_LEVEL=1\n   KMP_HOT_TEAMS_MODE=0\n   KMP_INIT_AT_FORK=true\n   KMP_LIBRARY=throughput\n   KMP_LOCK_KIND=queuing\n   KMP_MALLOC_POOL_INCR=1M\n   KMP_NUM_LOCKS_IN_BLOCK=1\n   KMP_PLAIN_BARRIER='2,2'\n   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n   KMP_REDUCTION_BARRIER='1,1'\n   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n   KMP_SCHEDULE='static,balanced;guided,iterative'\n   KMP_SETTINGS=true\n   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n   KMP_STACKOFFSET=64\n   KMP_STACKPAD=0\n   KMP_STACKSIZE=8M\n   KMP_STORAGE_MAP=false\n   KMP_TASKING=2\n   KMP_TASKLOOP_MIN_TASKS=0\n   KMP_TASK_STEALING_CONSTRAINT=1\n   KMP_TEAMS_THREAD_LIMIT=4\n   KMP_TOPOLOGY_METHOD=all\n   KMP_USE_YIELD=1\n   KMP_VERSION=false\n   KMP_WARNINGS=false\n   OMP_AFFINITY_FORMAT='OMP: pid %P tid %i thread %n bound to OS proc set {%A}'\n   OMP_ALLOCATOR=omp_default_mem_alloc\n   OMP_CANCELLATION=false\n   OMP_DEFAULT_DEVICE=0\n   OMP_DISPLAY_AFFINITY=false\n   OMP_DISPLAY_ENV=false\n   OMP_DYNAMIC=false\n   OMP_MAX_ACTIVE_LEVELS=1\n   OMP_MAX_TASK_PRIORITY=0\n   OMP_NESTED: deprecated; max-active-levels-var=1\n   OMP_NUM_THREADS: value is not defined\n   OMP_PLACES: value is not defined\n   OMP_PROC_BIND='intel'\n   OMP_SCHEDULE='static'\n   OMP_STACKSIZE=8M\n   OMP_TARGET_OFFLOAD=DEFAULT\n   OMP_THREAD_LIMIT=2147483647\n   OMP_WAIT_POLICY=PASSIVE\n   KMP_AFFINITY='verbose,warnings,respect,granularity=fine,compact,1,0'\n\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(tf.cast(train_img, tf.float32), np.array(pd.get_dummies(train_labels)), validation_split=0.1, epochs =20, verbose=1, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T12:57:06.399948Z","iopub.execute_input":"2024-05-08T12:57:06.400373Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/20\n81/81 [==============================] - 97s 1s/step - loss: 4.8320 - accuracy: 0.5037 - val_loss: 0.9972 - val_accuracy: 0.4564\nEpoch 2/20\n81/81 [==============================] - 96s 1s/step - loss: 0.7847 - accuracy: 0.6818 - val_loss: 0.9561 - val_accuracy: 0.5122\nEpoch 3/20\n81/81 [==============================] - 96s 1s/step - loss: 0.5886 - accuracy: 0.7681 - val_loss: 0.7801 - val_accuracy: 0.5645\nEpoch 4/20\n24/81 [=======>......................] - ETA: 1:06 - loss: 0.4245 - accuracy: 0.8320","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train_x, val_x, train_y, val_y = train_test_split(np.array(train_img), np.array(train_labels), test_size = 0.1)\ntrain_x.shape, train_y.shape, val_x.shape, val_y.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transforming_img = transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),  \n    transforms.Normalize([0.5,0.5,0.5], \n                        [0.5,0.5,0.5])\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_path = ('/kaggle/input/brain-tumor-classification-mri/Training/')\ntest_path = ('/kaggle/input/brain-tumor-classification-mri/Testing/')\n\ntrain_loader=DataLoader(\n    torchvision.datasets.ImageFolder(train_path,transform=transforming_img),\n    batch_size=64, shuffle=True\n)\ntest_loader=DataLoader(\n    torchvision.datasets.ImageFolder(test_path,transform=transforming_img),\n    batch_size=32, shuffle=True\n)\n\n\n#categories\nroot=pathlib.Path(train_path)\nclasses=sorted([j.name.split('/')[-1] for j in root.iterdir()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\n\ntrain_count=len(glob.glob(train_path+'/**/*.jpg'))\ntest_count=len(glob.glob(test_path+'/**/*.jpg'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the ConvNet model\nclass ConvNet(nn.Module):\n    def __init__(self, num_classes=4):\n        super(ConvNet, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(num_features=12)\n        self.relu1 = nn.ReLU()\n        self.pool = nn.MaxPool2d(kernel_size=2)\n        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(num_features=32)\n        self.relu3 = nn.ReLU()\n        self.fc1 = nn.Linear(in_features=75 * 75 * 32, out_features=128)\n        self.relu4 = nn.ReLU()\n        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n\n    def forward(self, input):\n        output = self.conv1(input)\n        output = self.bn1(output)\n        output = self.relu1(output)\n        output = self.pool(output)\n        output = self.conv2(output)\n        output = self.relu2(output)\n        output = self.conv3(output)\n        output = self.bn3(output)\n        output = self.relu3(output)\n        output = output.view(-1, 32 * 75 * 75)\n        output = self.fc1(output)\n        output = self.relu4(output)\n        output = self.fc2(output)\n        return output\n\n# Initialize model and set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = ConvNet(num_classes=4).to(device)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, (images,labels) in enumerate(train_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze all layers except the last fully connected layer\nfor name, param in model.named_parameters():\n    if 'fc2' not in name:\n        param.requires_grad = False\n\n# Define optimizer and loss function\noptimizer = Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\nloss_function = CrossEntropyLoss()\n\n# Fine-tuning loop\nfor epoch in range(12): \n    model.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n\n# Evaluation on the test dataset\nmodel.eval()\ntest_accuracy = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predictions = torch.max(outputs.data, 1)\n        test_accuracy += (predictions == labels).sum().item()\n        total_samples += labels.size(0)\n\nfinal_test_accuracy = test_accuracy / total_samples\nprint(f'Test Accuracy: {final_test_accuracy:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
